{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChattbotAndVoicebot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SDfOlDrKKYYq",
        "TlVJ6xS2LYJa",
        "n6oy3j4WM5xF"
      ],
      "authorship_tag": "ABX9TyPOD699dRdreJ5sOSFBmNqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinicius-Jose/Notebooks/blob/main/ChattbotAndVoicebot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDfOlDrKKYYq"
      },
      "source": [
        "# Instalando Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZouUqgA4J5Tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524ac66a-f1a5-4b44-9620-b5be8a56940b"
      },
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install SpeechRecognition\n",
        "!pip install pyaudio\n",
        "!pip install ffmpeg-python\n",
        "!pip install gTTS\n",
        "!pip install chatterbot\n",
        "!pip install chatterbot-corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1).\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.5).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.7/dist-packages (0.2.11)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gTTS) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gTTS) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gTTS) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2.10)\n",
            "Requirement already satisfied: chatterbot in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: sqlalchemy<1.4,>=1.3 in /usr/local/lib/python3.7/dist-packages (from chatterbot) (1.3.24)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from chatterbot) (2018.9)\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from chatterbot) (2.8.1)\n",
            "Requirement already satisfied: mathparse<0.2,>=0.1 in /usr/local/lib/python3.7/dist-packages (from chatterbot) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<2.9,>=2.8->chatterbot) (1.15.0)\n",
            "Requirement already satisfied: chatterbot-corpus in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: PyYAML<4.0,>=3.12 in /usr/local/lib/python3.7/dist-packages (from chatterbot-corpus) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LkAofHwKdTI"
      },
      "source": [
        "# Importaçoes necessarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS2GWmUSKQLr"
      },
      "source": [
        "import speech_recognition as sr\n",
        "from io import BytesIO\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "from time import sleep\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "from gtts import gTTS, lang\n",
        "from tempfile import TemporaryFile\n",
        "from IPython.core.display import display\n",
        "\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "from chatterbot import logic, comparisons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNoSt-kWKspY"
      },
      "source": [
        "# TTS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6Sqh6H1K45X"
      },
      "source": [
        "def tts(text,lang='pt',tld='com.br'):\n",
        "  response = gTTS(text ,lang=lang,tld=tld)\n",
        "  response.save(\"tts.wav\")\n",
        "  display(Audio(\"tts.wav\", autoplay=True)) \n",
        "  sleep(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlVJ6xS2LYJa"
      },
      "source": [
        "# Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCZb7sV8Lj3K"
      },
      "source": [
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLIJds98LwYH"
      },
      "source": [
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr2, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ELcfou7MVR-"
      },
      "source": [
        "def grava_audio(file_name):\n",
        "  samplerate = 44100; fs = 100\n",
        "\n",
        "  t = np.linspace(0., 1., samplerate)\n",
        "\n",
        "  amplitude = np.iinfo(np.int16).max\n",
        "\n",
        "  data = amplitude * np.sin(2. * np.pi * fs * t)\n",
        "  data, sr2 = get_audio()\n",
        "\n",
        "  write(file_name, samplerate, data.astype(np.int16)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggUEeAiCMfqg"
      },
      "source": [
        "def reconhecimento():\n",
        "  print('Lendo audio: \\n')\n",
        "  texto = None\n",
        "  file_name = \"reconhecimento.wav\"\n",
        "  grava_audio(file_name)\n",
        "  r = sr.Recognizer()\n",
        "\n",
        "  with sr.WavFile(file_name) as fonte:\n",
        "      audio = r.record(fonte)\n",
        "\n",
        "      texto = r.recognize_google(audio, language='pt-BR')\n",
        "\n",
        "      try:\n",
        "          print(texto)\n",
        "          print('Áudio reconhecido GOOGLE: \\n ' + texto.capitalize() + '\\n')\n",
        "\n",
        "      except Exception:\n",
        "          print('Nao foi possivel compreender o audio')\n",
        "  return texto\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6oy3j4WM5xF"
      },
      "source": [
        "# Chatterbot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqMkcB_-M-IA"
      },
      "source": [
        "bot = ChatBot('Tony',logic_adapters=[{\n",
        "        \"import_path\": \"chatterbot.logic.BestMatch\",\n",
        "        \"statement_comparison_function\": comparisons.LevenshteinDistance}\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5RGE12tNFfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fecc83f-2876-4c28-f273-11f5b1646d77"
      },
      "source": [
        "trainer = ChatterBotCorpusTrainer(bot)\n",
        "trainer.train(\"chatterbot.corpus.portuguese\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training compliment.yml: [####################] 100%\n",
            "Training conversations.yml: [####################] 100%\n",
            "Training greetings.yml: [####################] 100%\n",
            "Training linguistic_knowledge.yml: [####################] 100%\n",
            "Training proverbs.yml: [####################] 100%\n",
            "Training suggestions.yml: [####################] 100%\n",
            "Training trivia.yml: [####################] 100%\n",
            "Training unilab.yml: [####################] 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF0rzvGVNGXI"
      },
      "source": [
        "trainer.export_for_training('./my_export.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbFgK2JENPSV"
      },
      "source": [
        "# Execuçao do Chatbott e VoiceBot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0HlAn3nNjBa"
      },
      "source": [
        "def chatbot():\n",
        "  while True:\n",
        "    pergunta = input(\"Usuário: \")\n",
        "    resposta = bot.get_response(pergunta)\n",
        "    if float(resposta.confidence) > 0.5:\n",
        "        print('TW Bot: ', resposta)\n",
        "    else:\n",
        "        print('TW Bot: Ainda não sei responder esta pergunta')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9jYC2uvN7j7"
      },
      "source": [
        "def voicebot():\n",
        "  while True:\n",
        "    pergunta = reconhecimento()\n",
        "    resposta = bot.get_response(pergunta)\n",
        "    if float(resposta.confidence) > 0.5:\n",
        "        tts(resposta.text)\n",
        "    else:\n",
        "        tts('Ainda não sei responder esta pergunta')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFvlxRAoNUq6"
      },
      "source": [
        "a = int(input('Voce deseja conversar por voz ou texto? Digite: 1-Voz 2-Texto '))\n",
        "\n",
        "if a == 1:\n",
        "  voicebot()\n",
        "elif a == 2:\n",
        "  chatbot()\n",
        "else:\n",
        "  print('Opcao invalida encerrando sistema')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}